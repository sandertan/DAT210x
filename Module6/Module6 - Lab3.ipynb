{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module6- Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is intentionally missing! Read the directions on the course lab page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/parkinsons.data')\n",
    "y = X['status']\n",
    "X.drop(['name', 'status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02971</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04368</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03590</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03772</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04465</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0      119.992       157.302        74.997         0.00784           0.00007   \n",
       "1      122.400       148.650       113.819         0.00968           0.00008   \n",
       "2      116.682       131.111       111.555         0.01050           0.00009   \n",
       "3      116.676       137.871       111.366         0.00997           0.00009   \n",
       "4      116.014       141.781       110.655         0.01284           0.00011   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)    ...     \\\n",
       "0   0.00370   0.00554     0.01109       0.04374             0.426    ...      \n",
       "1   0.00465   0.00696     0.01394       0.06134             0.626    ...      \n",
       "2   0.00544   0.00781     0.01633       0.05233             0.482    ...      \n",
       "3   0.00502   0.00698     0.01505       0.05492             0.517    ...      \n",
       "4   0.00655   0.00908     0.01966       0.06425             0.584    ...      \n",
       "\n",
       "   MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE       DFA   spread1  \\\n",
       "0   0.02971      0.06545  0.02211  21.033  0.414783  0.815285 -4.813031   \n",
       "1   0.04368      0.09403  0.01929  19.085  0.458359  0.819521 -4.075192   \n",
       "2   0.03590      0.08270  0.01309  20.651  0.429895  0.825288 -4.443179   \n",
       "3   0.03772      0.08771  0.01353  20.644  0.434969  0.819235 -4.117501   \n",
       "4   0.04465      0.10470  0.01767  19.649  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81355932203389836"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That accuracy was just too low to be useful. We need to get it up. One way you could go about doing that would be to manually try a bunch of combinations of C, and gamma values for your rbf kernel. But that could literally take forever. Also, you might unknowingly skip a pair of values that would have resulted in a very good accuracy.\n",
    "\n",
    "Instead, lets get the computer to do what computers do best. Program a naive, best-parameter search by creating nested for-loops. The outer for-loop should iterate a variable C from  to , using  unit increments. The inner for-loop should increment a variable gamma from to , using  unit increments. As you know, Python ranges won't allow for float intervals, so you'll have to do some research on NumPy ARanges, if you don't already know how to use them.\n",
    "\n",
    "Since the goal is to find the parameters that result in the model having the best accuracy score, you'll need a best_score = 0 variable that you initialize outside of the for-loops. Inside the inner for-loop, create an SVC model and pass in the C and gamma parameters its class constructor. Train and score the model appropriately. If the current best_score is less than the model's score, update the best_score being sure to print it out, along with the C and gamma values that resulted in it.\n",
    "\n",
    "After running your assignment again, what is the highest accuracy score you are able to get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_range = np.arange(0.05, 2, 0.05)\n",
    "gamma_range = np.arange(0.001, 0.1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = 0\n",
    "best_gamma = 0\n",
    "best_score = 0\n",
    "\n",
    "for c in c_range:\n",
    "    for gamma in gamma_range:\n",
    "        model = svm.SVC(C=c, gamma=gamma, kernel='rbf')\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_c = c\n",
    "            best_gamma = gamma\n",
    "            best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65\n",
      "0.005\n",
      "0.915254237288\n"
     ]
    }
   ],
   "source": [
    "print(best_c)\n",
    "print(best_gamma)\n",
    "print(best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the units on those columns: Hz, %, Abs, dB, etc. What happened to transforming your data? With all of those units interacting with one another, some pre-processing is surely in order.\n",
    "\n",
    "Right after you preform the train/test split but before you train your model, inject SciKit-Learn's pre-processing code. Unless you have a good idea which one is going to work best, you're going to have to try the various pre-processors one at a time, checking to see if they improve your predictive accuracy.\n",
    "\n",
    "Experiment with Normalizer(), MaxAbsScaler(), MinMaxScaler(), KernelCenterer(), and StandardScaler().\n",
    "\n",
    "After trying all of these scalers, what is the new highest accuracy score you're able to achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [preprocessing.Normalizer(),\n",
    "           preprocessing.MaxAbsScaler(),\n",
    "           preprocessing.MinMaxScaler(),\n",
    "           preprocessing.KernelCenterer(),\n",
    "           preprocessing.StandardScaler()]\n",
    "c_range = np.arange(0.05, 2, 0.05)\n",
    "gamma_range = np.arange(0.001, 0.1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = 0\n",
    "best_gamma = 0\n",
    "best_score = 0\n",
    "\n",
    "for scaler in scalers:\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "    \n",
    "    # Normalize\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Loop over c and gamma\n",
    "    for c in c_range:\n",
    "        for gamma in gamma_range:\n",
    "            model = svm.SVC(C=c, gamma=gamma, kernel='rbf')\n",
    "            model.fit(X_train, y_train)\n",
    "            score = model.score(X_test, y_test)\n",
    "            if score > best_score:\n",
    "                best_c = c\n",
    "                best_gamma = gamma\n",
    "                best_score = score\n",
    "                best_scaler = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.55\n",
      "0.097\n",
      "0.932203389831\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "print(best_c)\n",
    "print(best_gamma)\n",
    "print(best_score)\n",
    "print(best_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score keeps creeping upwards. Let's have one more go at it. Remember how in a previous lab we discovered that SVM's are a bit sensitive to outliers and that just throwing all of our unfiltered, dirty or noisy data at it, particularly in high-dimensionality space, can actually cause the accuracy score to suffer?\n",
    "\n",
    "Well, let's try to get rid of some useless features. Immediately after you do the pre-processing, run PCA on your dataset. The original dataset has 22 columns and 1 label column. So try experimenting with PCA n_component values between 4 and 14. Are you able to get a better accuracy?\n",
    "\n",
    "If you are not, then forget about PCA entirely. However if you are able to get a higher score, then be *sure* keep that accuracy score in mind, and comment out all the PCA code for now.\n",
    "\n",
    "In the same spot, run Isomap on the data. Manually experiment with every inclusive combination of n_neighbors between 2 and 5, and n_components between 4 and 6. Are you able to get a better accuracy?\n",
    "\n",
    "If you are not, then forget about isomap entirely. However if you are able to get a higher score, then be *sure* keep that figure in mind.\n",
    "\n",
    "If either PCA or Isomap helped you out, then uncomment out the appropriate transformation code so that you have the highest accuracy possible.\n",
    "\n",
    "What is your highest accuracy score on this assignment to date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components = range(4,14,1)\n",
    "\n",
    "best_c = 0\n",
    "best_gamma = 0\n",
    "best_score = 0\n",
    "best_pca_components = 0\n",
    "\n",
    "\n",
    "for scaler in scalers:\n",
    "    for n_components in pca_components:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "\n",
    "        # Normalize\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "        # Reduce dimensionality\n",
    "        pca_model = PCA(n_components=n_components, random_state=7)\n",
    "        pca_model.fit(X_train)\n",
    "        X_train = pca_model.transform(X_train)\n",
    "        X_test = pca_model.transform(X_test)\n",
    "\n",
    "        # Loop over c and gamma\n",
    "        for c in c_range:\n",
    "            for gamma in gamma_range:\n",
    "                model = svm.SVC(C=c, gamma=gamma, kernel='rbf')\n",
    "                model.fit(X_train, y_train)\n",
    "                score = model.score(X_test, y_test)\n",
    "                if score > best_score:\n",
    "                    best_c = c\n",
    "                    best_gamma = gamma\n",
    "                    best_score = score\n",
    "                    best_scaler = scaler\n",
    "                    best_pca_components = n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65\n",
      "0.098\n",
      "0.932203389831\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(best_c)\n",
    "print(best_gamma)\n",
    "print(best_score)\n",
    "print(best_scaler)\n",
    "print(best_pca_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap_components = range(4,14,1)\n",
    "isomap_neighbors = range(4,6,1)\n",
    "\n",
    "best_c = 0\n",
    "best_gamma = 0\n",
    "best_score = 0\n",
    "best_pca_components = 0\n",
    "\n",
    "\n",
    "for scaler in scalers:\n",
    "    \n",
    "    # Reduce dimensionality\n",
    "    for n_components in isomap_components:\n",
    "        \n",
    "        for n_neighbors in isomap_neighbors:\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "    \n",
    "            # Normalize\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            isomap_model = Isomap(n_neighbors=n_neighbors, n_components = n_components)\n",
    "\n",
    "            isomap_model.fit(X_train)\n",
    "            X_train = isomap_model.transform(X_train)\n",
    "            X_test = isomap_model.transform(X_test)\n",
    "\n",
    "            # Loop over c and gamma\n",
    "            for c in c_range:\n",
    "                for gamma in gamma_range:\n",
    "                    model = svm.SVC(C=c, gamma=gamma, kernel='rbf')\n",
    "                    model.fit(X_train, y_train)\n",
    "                    score = model.score(X_test, y_test)\n",
    "                    if score > best_score:\n",
    "                        best_c = c\n",
    "                        best_gamma = gamma\n",
    "                        best_score = score\n",
    "                        best_scaler = scaler\n",
    "                        best_isomap_components = n_components\n",
    "                        best_isomap_neighbors = n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15\n",
      "0.098\n",
      "0.949152542373\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(best_c)\n",
    "print(best_gamma)\n",
    "print(best_score)\n",
    "print(best_scaler)\n",
    "print(best_isomap_components)\n",
    "print(best_isomap_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
